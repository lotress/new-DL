{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNQ12hrbapFx"
   },
   "source": [
    "## Preparation\n",
    "\n",
    "Using with Google Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ivcWodHhapF2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "!cp '/gdrive/My Drive/data.7z' ./\n",
    "!cp '/gdrive/My Drive/address/simhei.ttf' /usr/share/fonts/\n",
    "!7z x data.7z\n",
    "!rm -f data.7z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file data.py\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "dataLength = {'train': 65536, 'val': 256, 'test': 256}\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super(Data, self).__init__()\n",
    "        l = dataLength[path]\n",
    "        self.lens = torch.randint(4, (l,)) + 1\n",
    "        self.mask = torch.zeros((l, 5), dtype=torch.uint8)\n",
    "        for i in range(l):\n",
    "            self.mask[i, :self.lens[i]].fill_(1)\n",
    "        self.data = torch.rand((l, 5)) * self.mask.float()\n",
    "        self.count = l\n",
    "    def __len__(self):\n",
    "        return self.count\n",
    "    # input, label, length, mask\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.data[ind]\n",
    "        return x, x.sum(), self.lens[ind], self.mask[ind]\n",
    "\n",
    "newLoader = lambda path, *args, **kwargs: DataLoader(Data(path), *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pmj1FdGVapF_",
    "outputId": "9cae251b-ecb2-4807-a199-e059d8af021a"
   },
   "outputs": [],
   "source": [
    "%%file train.py\n",
    "import os\n",
    "import argparse\n",
    "from functools import reduce\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "parser.add_argument(\"--rank\", type=int, default=0)\n",
    "args = parser.parse_known_args()[0]\n",
    "def opt():pass\n",
    "if torch.cuda.is_available():\n",
    "  opt.dtype = torch.half\n",
    "  opt.device = torch.device('cuda:{}'.format(args.local_rank))\n",
    "  torch.cuda.set_device(args.local_rank)\n",
    "  opt.cuda = True\n",
    "else:\n",
    "  opt.device = torch.device('cpu')\n",
    "  opt.dtype = torch.float\n",
    "  opt.cuda = False\n",
    "  num_threads = torch.multiprocessing.cpu_count() - 1\n",
    "  if num_threads > 1:\n",
    "    torch.set_num_threads(num_threads)\n",
    "print('Using device ' + str(opt.device))\n",
    "print('Using default dtype ' + str(opt.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vocab.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file vocab.py\n",
    "import os\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "vocabPath = './char.txt'\n",
    "\n",
    "def getBatch(data):\n",
    "  x = pad_sequence([torch.tensor([1] + [(vocabIndex[t] if t in vocabSet else 0) for t in s] + [0], dtype=torch.long) for s in data])\n",
    "  l = [len(s) + 1 for s in data]\n",
    "  mask = torch.ones_like(x)\n",
    "  for i, t in enumerate(l):\n",
    "    mask[t:, i].fill_(0)\n",
    "  return x, l, mask\n",
    "\n",
    "def initial(path):\n",
    "  global vocab, vocabSet, vocabIndex\n",
    "  with open(path, 'r', encoding='utf-8') as f:\n",
    "    vocab = ['', ''] + f.read().split('\\0')\n",
    "  vocabSet = set(vocab)\n",
    "  vocabIndex = {}\n",
    "  for i, w in enumerate(vocab):\n",
    "    vocabIndex[w] = i\n",
    "  return vocab\n",
    "\n",
    "vocab = []\n",
    "if os.path.exists(vocabPath):\n",
    "  initial(vocabPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fjZ72UV0apF8"
   },
   "outputs": [],
   "source": [
    "%%file -a train.py\n",
    "word2vecPath = './vectors.pth'\n",
    "stateDictPath = './net.init.pth'\n",
    "fontPath = '/usr/share/fonts/simhei.ttf'\n",
    "vocabPath = './char.txt'\n",
    "#fontPath = '/usr/share/fonts/wqy-microhei/wqy-microhei.ttc'\n",
    "#fontPath = 'C:/Windows/Fonts/simhei.ttf'\n",
    "from vocab import vocab, initial\n",
    "initial(vocabPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "Zero = torch.tensor(0.)\n",
    "maxLen = 5\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(Model, self).__init__()\n",
    "        self.device = opt.device\n",
    "        self.dtype = opt.dtype\n",
    "        self.edim = opt.edim\n",
    "        self.dropout = nn.Dropout(opt.dropout)\n",
    "        self.to(dtype=opt.dtype, device=opt.device)\n",
    "        self.f0 = nn.Linear(1, opt.edim, bias=True)\n",
    "        self.act0 = nn.LeakyReLU(.1)\n",
    "        self.norm = nn.BatchNorm1d(opt.edim * maxLen, affine=False)\n",
    "        self.f1 = nn.Linear(opt.edim * maxLen, 1, bias=True)\n",
    "        self.act1 = torch.tanh\n",
    "\n",
    "    def forward(self, x, mask, *_):\n",
    "        bsz, l = x.shape\n",
    "        mask = mask.to(self.dtype)\n",
    "        e = self.dropout(x).view(bsz, l, 1)\n",
    "        x1 = self.act0(self.f0(e)) * mask.view(bsz, l, 1)\n",
    "        x2 = self.norm(x1.view(bsz, -1)).view(bsz, l, -1) * mask.view(bsz, l, 1)\n",
    "        return self.act1(self.f1(x2.view(bsz, -1)).squeeze(-1)), Zero, x1\n",
    "\n",
    "predict = lambda x: x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dPcJLrxMr9Y"
   },
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbO5FH4NapGB"
   },
   "outputs": [],
   "source": [
    "%%file -a train.py\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from data import newLoader\n",
    "from model import Model, predict\n",
    "from option import option\n",
    "torch.manual_seed(args.rank)\n",
    "np.random.seed(args.rank)\n",
    "getNelement = lambda model: sum(map(lambda p: p.nelement(), model.parameters()))\n",
    "l1Reg = lambda acc, cur: acc + cur.abs().sum(dtype=torch.float)\n",
    "l2Reg = lambda acc, cur: acc + (cur * cur).sum(dtype=torch.float)\n",
    "nan = torch.tensor(float('nan'), device=opt.device)\n",
    "\n",
    "opt.batchsize = 1\n",
    "opt.epochs = 1\n",
    "opt.maxgrad = 1. # max gradient\n",
    "opt.dropout = 0\n",
    "opt.sdt = 0.001 # initial learning rate\n",
    "opt.sdt_decay_step = 10 # how often to reduce learning rate\n",
    "opt.criterion = lambda y, out, mask: F.mse_loss(out, y) # criterion for evaluation\n",
    "opt.loss = lambda opt, model, y, out, *args: F.mse_loss(out, y) # criterion for loss function\n",
    "opt.newOptimizer = lambda opt, params, eps: optim.Adam(params, lr=opt.sdt, amsgrad=True, eps=eps)\n",
    "opt.writer = 0 # TensorBoard writer\n",
    "opt.drawVars = 0\n",
    "opt.reset_parameters = 0\n",
    "opt.__dict__.update(option)\n",
    "\n",
    "def initParameters(opt, model):\n",
    "    for m in model.modules():\n",
    "        if hasattr(m, 'bias') and isinstance(m.bias, torch.Tensor):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        if isinstance(m, nn.PReLU):\n",
    "            nn.init.constant_(next(m.parameters()), 1)\n",
    "        if opt.reset_parameters:\n",
    "            opt.reset_parameters()\n",
    "    if hasattr(model, 'embedding') and isinstance(model.embedding, nn.Embedding):\n",
    "        model.embedding.weight.data[2:] = torch.load(word2vecPath)\n",
    "\n",
    "def trainStep(opt, model, x, y, length, mask):\n",
    "    opt.optimizer.zero_grad()\n",
    "    x = x.to(opt.device, non_blocking=True)\n",
    "    mask = mask.to(opt.device, non_blocking=True)\n",
    "    label = y.to(opt.device, dtype=torch.float, non_blocking=True)\n",
    "    loss = opt.loss(opt, model, label, *model(x, mask))\n",
    "    if torch.allclose(loss, nan, equal_nan=True):\n",
    "        raise Exception('Loss returns NaN')\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_value_(model.parameters(), opt.maxgrad)\n",
    "    opt.optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "def evaluateStep(opt, model, x, y, _, mask):\n",
    "    out, *others = model(x, mask)\n",
    "    pred = predict(out)\n",
    "    missed = opt.criterion(y, pred, mask)\n",
    "    return (float(missed.sum()), missed, pred, *others)\n",
    "\n",
    "def evaluate(opt, model):\n",
    "    model.eval()\n",
    "    totalErr = 0\n",
    "    count = 0\n",
    "    for x, y, l, mask in newLoader('val', batch_size=opt.batchsize):\n",
    "        count += int(l.sum())\n",
    "        err, _, pred, _, *others = evaluateStep(opt, model, x, y, l, mask)\n",
    "        totalErr += err\n",
    "    if opt.drawVars:\n",
    "        opt.drawVars(x[0], l[0], *tuple(v[0] for v in others))\n",
    "        print(pred[0])\n",
    "    return totalErr / count\n",
    "\n",
    "def initTrain(opt, model, epoch=None):\n",
    "    eps = 1e-4 if opt.dtype == torch.float16 else 1e-8\n",
    "    opt.optimizer = opt.newOptimizer(opt, model.parameters(), eps)\n",
    "    if opt.sdt_decay_step > 0:\n",
    "        opt.scheduler = optim.lr_scheduler.StepLR(opt.optimizer, opt.sdt_decay_step, gamma=0.5)\n",
    "    else:\n",
    "        opt.scheduler = optim.lr_scheduler.StepLR(opt.optimizer, 1e6, gamma=1)\n",
    "    if type(epoch) == int:\n",
    "        state = torch.load('train.epoch{}.pth'.format(epoch), map_location='cpu')\n",
    "        opt.optimizer.load_state_dict(state[0])\n",
    "        opt.scheduler.load_state_dict(state[1])\n",
    "    else:\n",
    "        torch.manual_seed(args.rank)\n",
    "        np.random.seed(args.rank)\n",
    "\n",
    "def train(opt, model, init=True):\n",
    "    if init:\n",
    "        initParameters(opt, model)\n",
    "        if type(init) == int:\n",
    "            model.load_state_dict(torch.load('model.epoch{}.pth'.format(epoch), map_location='cpu'))\n",
    "            model.to(device=opt.device, dtype=opt.dtype) # need before constructing optimizers\n",
    "        initTrain(opt, model, init)\n",
    "    else:\n",
    "        model.to(device=opt.device, dtype=opt.dtype)\n",
    "    for i in range(opt.scheduler.last_epoch, opt.epochs):\n",
    "        opt.scheduler.step()\n",
    "        count = 0\n",
    "        totalLoss = 0\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        for x, y, l, mask in newLoader('train', batch_size=opt.batchsize, shuffle=True):\n",
    "            length = int(l.sum())\n",
    "            count += length\n",
    "            loss = trainStep(opt, model, x, y, length, mask)\n",
    "            totalLoss += loss\n",
    "        valErr = evaluate(opt, model)\n",
    "        if opt.writer:\n",
    "            logBoardStep(opt, model)\n",
    "        print('Epoch #%i | train loss: %.4f | valid error: %.3f | learning rate: %.5f' %\n",
    "          (opt.scheduler.last_epoch, totalLoss / count, valErr, opt.scheduler.get_lr()[0]))\n",
    "        if i % 10 == 9:\n",
    "            saveState(opt, model, opt.scheduler.last_epoch)\n",
    "    return valErr\n",
    "\n",
    "def saveState(opt, model, epoch):\n",
    "    torch.save(model.state_dict(), 'model.epoch{}.pth'.format(epoch))\n",
    "    torch.save((opt.optimizer.state_dict(), opt.scheduler.state_dict()), 'train.epoch{}.pth'.format(epoch))\n",
    "\n",
    "def logBoardStep(opt, model):\n",
    "    step = opt.scheduler.last_epoch\n",
    "    for name, param in model.named_parameters():\n",
    "        try:\n",
    "            opt.writer.add_histogram(name, param.data, step)\n",
    "        except:\n",
    "            print(name, param)\n",
    "\n",
    "torch.manual_seed(args.rank)\n",
    "np.random.seed(args.rank)\n",
    "model = Model(opt)\n",
    "print('Number of parameters: %i | valid error: %.3f' % (getNelement(model), evaluate(opt, model)))\n",
    "train(opt, model)\n",
    "torch.save(model.state_dict(), 'model.epoch{}.pth'.format(opt.scheduler.last_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file option.py\n",
    "option = dict(edim=16, epochs=10, maxgrad=1., sdt=1e-2, sdt_decay_step=3, batchsize=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_qdhhFzPwUg"
   },
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rcxDyQ52Ap4"
   },
   "outputs": [],
   "source": [
    "%%file -a option.py\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib as mpl\n",
    "zhfont= mpl.font_manager.FontProperties(fname=fontPath)\n",
    "columns = 2\n",
    "\n",
    "def drawAttention(indices, l, _, att, *args):\n",
    "  if len(att.shape) != 3:\n",
    "    return\n",
    "  heads = att.size(0)\n",
    "  l = int(l)\n",
    "  rows = (heads + columns - 1) // columns\n",
    "  indices = indices[:l].tolist()\n",
    "  ticks = np.arange(0, l)\n",
    "  labels = [''] + [vocab[i] for i in indices]\n",
    "  fig = plt.figure(figsize=(16, rows * 16 // columns))\n",
    "  for t in range(heads):\n",
    "    ax = fig.add_subplot(rows, columns, t + 1)\n",
    "    data = att[t, :l, :l+1].detach().to(torch.float).cpu().numpy()\n",
    "    cax = ax.matshow(data, interpolation='nearest', cmap='hot', vmin=0, vmax=1)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.set_xticklabels(labels + ['NA'], fontproperties=zhfont)\n",
    "    ax.set_yticklabels(labels, fontproperties=zhfont)\n",
    "  return plt.show()\n",
    "\n",
    "option['drawVars'] = drawAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i train.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
